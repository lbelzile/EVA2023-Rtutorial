{"title":"Tutorial on Statistical Computing for Extremes with **R**","markdown":{"yaml":{"title":"Tutorial on Statistical Computing for Extremes with **R**","author":"Léo Belzile","subtitle":"Likelihood-based inference for univariate extremes","date":"June 30, 2023","eval":true,"echo":true,"format":{"revealjs":{"slide-number":true,"preview-links":"auto","theme":["simple","hecmontreal.scss"],"title-slide-attributes":{"data-background-color":"#002855"}}},"bibliography":"EVA2023-software.bib"},"headingText":"Plan for today","headingAttr":{"id":"","classes":[],"keyvalue":[["background-color","`r pcols['bleu']`"],[".white",""]]},"containsRefs":false,"markdown":"\n\n\n```{r include=FALSE}\n\nhecbleu <- c(\"#002855\")\nfcols <- c(gris = \"#888b8d\",\n           bleu = \"#0072ce\",\n           aqua = \"#00aec7\",\n           vert = \"#26d07c\",\n           rouge = \"#ff585d\",\n           rose = \"#eb6fbd\",\n           jaune = \"#f3d03e\")\npcols <- c(gris = \"#d9d9d6\",\n           bleu = \"#92c1e9\",\n           agua = \"#88dbdf\",\n           vert = \"#8fe2b0\",\n           rouge = \"#ffb1bb\",\n           rose = \"#eab8e4\",\n           jaune = \"#f2f0a1\")\n\nknitr::opts_chunk$set(fig.retina = 3, collapse = TRUE)\noptions(digits = 3, width = 75)\n```\n\n<!--\n\n:::: {.columns}\n\n::: {.column width=\"40%\"}\n\n- Univariate extremes\n  - Maximum likelihood\n  - Bayesian\n  - Semiparametric methods\n- Regression models\n\n:::\n\n::: {.column width=\"40%\"}\n\n- Conditional extremes\n- Models for time series\n\n:::\n\n::::\n\n-->\n\n## Extremal type theorem\n\nConsider $Y_i$ $(i=1,2,\\ldots)$ i.i.d. with distribution $F$. \n\nIf there exist normalizing sequences $a_n>0$ and $b_n \\in \\mathbb{R}$ such that\n\\begin{align}\n \\lim_{n \\to \\infty} \\Pr\\left(\\frac{\\max_{i=1}^n Y_i - b_n}{a_n} \\leq x \\right) = G(x),\n\\label{eq:gevconv}\n\\end{align}\nfor $G$ a non-degenerate distribution, then $G$ must be **generalized extreme value** (GEV).\n\n## Generalized extreme value distribution\nWith location $\\mu \\in \\mathbb{R}$, scale $\\sigma \\in \\mathbb{R}_{+}$ and shape $\\xi \\in \\mathbb{R}$ parameters, the distribution function is\n\\begin{align*}\nG(x) =\\begin{cases}\n \\exp\\left\\{-\\left(1+\\xi \\frac{x-\\mu}{\\sigma}\\right)^{-1/\\xi}_{+}\\right\\}, & \\xi \\neq 0;\\\\\n\\exp\\left\\{-\\exp\\left(-\\frac{x-\\mu}{\\sigma}\\right)\\right\\}, & \\xi = 0,\n\\end{cases}\n\\end{align*}\nwhere $x_{+} = \\max\\{x, 0\\}$.\n\nThe support is $\\{x \\in \\mathbb{R}: \\xi(x-\\mu)/\\sigma > -1\\}$.\n\n## Max-stability property\n\nIf $Y_i \\sim \\mathsf{GEV}(\\mu, \\sigma, \\xi)$ are independent, then $$\\max_{i=1}^N Y_i \\sim \\mathsf{GEV}(\\mu_N, \\sigma_N, \\xi),$$ where\n\n- $\\mu_N = \\mu + \\sigma(N^\\xi-1)/\\xi$\n- $\\sigma_N = \\sigma N^\\xi$\n\n(case $\\xi=0$ defined by continuity).\n\n\n\n\n\n## Block maximum\n\nWe can \n\n- partition data into blocks of roughly equal size $m$ and \n- fit a GEV distribution to the maximum of the blocks.\n\n```{r}\n#| eval: true\n#| echo: true \nlibrary(mev)\nlibrary(xts)\nlibrary(lubridate)\ndata(frwinds, package = \"mev\")\nlyon <- with(frwind, \n             xts(x = S2, order.by = date))\n# Create series of yearly maximum\nymax <- apply.yearly(lyon, max)\n```\n\n## Basics of likelihoods\n\n- Denote by $\\boldsymbol{\\theta} \\in \\mathcal{S} \\subseteq \\mathbb{R}^p$ the parameter vector.\n- Assume data has joint density $f(\\boldsymbol{y}; \\boldsymbol{\\theta})$.\n- The log likelihood is $\\ell(\\boldsymbol{\\theta}) = \\log f(\\boldsymbol{y}; \\boldsymbol{\\theta})$.\n- If the $n$ observations are independent with density or mass function $f_i$, then $\\ell(\\boldsymbol{\\theta}) = \\sum_{i=1}^n \\log f_i(y_i; \\boldsymbol{\\theta})$.\n- The maximum likelihood estimate $\\widehat{\\boldsymbol{\\theta}}$ is found by maximizing (numerically) $\\ell(\\boldsymbol{\\theta})$.\n\n---\n\n\n\n## Fitting GEV using `mev` package\n\n```{r}\n#| eval: true\n#| echo: true\nopt_gev <- mev::fit.gev(xdat = ymax, show = TRUE)\nmle <- coef(opt_gev)\n```\n\n## Goodness-of-fit diagnostics\n\nCustom methods (`print`, `plot`, `coef`, etc.) are defined\n\n```{r}\nmethods(class = \"mev_gev\")\npar(mfrow = c(1,2))\nplot(opt_gev)\n```\n\n\n## Numerical tricks\n\n- Standardize observations (e.g., `scale`) to facilitate optimization --- the GEV is a location-scale family.\n- Even if the limit is continuous and well defined at $\\xi=0$, the log likelihood and it's derivatives involves terms of the form $\\log(1+\\xi x)$, which are numerically unstable when $\\xi \\to 0$.\n  - Pro tip: do not code the likelihood yourself! Otherwise,\n    - use high precision arithmetic, e.g., `log1p`\n    - replace the terms that blow up by Taylor series expansion near $\\xi=0$ (interpolation).\n\n## Why use maximum likelihood?\n\n- Easy to generalize to complex settings (nonstationarity, regression models, censoring, rounding, etc.)\n- Known to be asymptotically most efficient (Cramér-Rao bound), even if they can be biased.\n- Point estimators, etc. are invariant to reparametrization.\n\n## Invariance property of maximum likelihood\n\nIf $h$ is a mapping, then $h(\\widehat{\\boldsymbol{\\theta}})$ is the MLE of $h(\\boldsymbol{\\theta})$.\n\nThe expected value of the $N=50$-years maximum for $\\xi < 1$, is  \\begin{align*}\\mathfrak{e}_N = h(\\mu, \\sigma, \\xi) = \\mu_N + \\sigma_N\\{\\Gamma(1-\\xi)-1\\}/\\xi.\n\\end{align*}\n\n\nThus, the MLE $\\widehat{\\mathfrak{e}}_N=h(\\widehat{\\mu}, \\widehat{\\sigma}, \\widehat{\\xi})$.\n\n```{r}\n# MLE of expectation of maximum of 50 blocks\ngev.mle(xdat = ymax, args = \"Nmean\", N = 50)\n```\n\n\n\n\n## Score vector\n\nWhen the log likelihood is differentiable, the MLE is the root of the score equation, meaning $\\ell_{\\boldsymbol{\\theta}}(\\widehat{\\boldsymbol{\\theta}}) = \\partial \\ell(\\boldsymbol{\\theta}) / \\partial \\boldsymbol{\\theta} = \\boldsymbol{0}_p$.\n\n\n```{r}\n#| eval: true\n#| echo: true\nmev::gev.score(par = mle, dat = ymax) # score\n```\n\n- Gradient-based algorithms exploit this feature for  optimization\n- but beware of support constraints!\n\nBest to reparametrize so that the parameter space is $\\mathbb{R}^p$ if possible.\n\n\n## Information matrix and standard errors\n\nWe can extract standard errors by taking the square root of the diagonal elements of the inverse of either\n\n- the Fisher information, $\\imath(\\boldsymbol{\\theta}) = \\mathsf{Cov}\\{\\ell_{\\boldsymbol{\\theta}}(\\boldsymbol{\\theta})\\}$ or\n- the observed information $\\jmath(\\boldsymbol{\\theta}) = - \\partial^2 \\ell(\\boldsymbol{\\theta})/ \\partial \\boldsymbol{\\theta} \\partial \\boldsymbol{\\theta}^\\top$,\n\nboth evaluated at the MLE $\\widehat{\\boldsymbol{\\theta}}$.\n\n\n```{r}\n#| eval: true\n#| echo: true\n# Compute observed information matrix\njmat <- mev::gev.infomat(par = mle, dat = ymax)\n# Compute standard errors\nsqrt(diag(solve(jmat)))\n# Compare with opt$std.err\n```\n\n## Some remarks\n\nWe may compute $j(\\widehat{\\boldsymbol{\\theta}})$ (the negative Hessian of log likelihood) numerically through finite differences.\n\nMany software implementations compute MLE via Nelder--Mead simplex algorithm: \n\n- check the gradient and/or\n- the log likelihood differences\n\nto make sure the optimisation was successful.\n\n## Properties of MLE\n\n\n- Maximum likelihood estimators are asymptotically Gaussian whenever $\\xi > -1/2$ with data in domain of attraction of extreme value distribution.\n- Consistency requires that one increases block size, etc. as $n$ increases at a particular rate depending on $F$.\n\n\n\n## Regularity conditions\n\nSome cumulants (moments of derivatives of the log likelihood) of extreme value models do not exist.\n\n- the MLE does not solve the score equation if $\\widehat{\\xi} \\leq -1$\n- MLE is not unique for $\\xi < -1$ (some combinations of $\\mu$ and $\\sigma$ yield infinite log likelihood). \n   - restrict the parameter space to $\\{\\boldsymbol{\\theta}: y_1, \\ldots, y_n \\in \\mathrm{supp}(\\boldsymbol{\\theta}), \\xi \\geq -1\\}$\n   - For GEV, MLE at boundary is $(\\widehat{\\mu}=\\overline{y}, \\widehat{\\sigma} = \\max(y) - \\overline{y}, \\xi=-1)$.\n\n## Regularity conditions\n\n   \nIf $\\widehat{\\xi} < -1/2$, cannot evaluate the information matrix.\n\n- Regularity assumptions do not apply! reported  std. errors are misleading.\n- Typically faster convergence, joint limit not asymptotically normal [@Smith:1985].\n\nIn applications, shape is typically close to zero, so authors sometimes restrict $\\xi \\in (-0.5, 0.5)$. \n\nPenalization of the shape helps ensure that we get reasonable estimates in small samples.\n\n## Profile log likelihood\n\nConsider a functional of interest $\\psi$ and other parameters $\\boldsymbol{\\lambda}$, treated as nuisance.\n\nWe reparametrize the log likelihood in terms of $(\\psi, \\boldsymbol{\\lambda})$ and compute  the profile log likelihood\n\\begin{align*}\n\\ell_{\\mathrm{p}}(\\psi) = \\max_{\\boldsymbol{\\lambda}} \\ell(\\psi, \\boldsymbol{\\lambda})\n\\end{align*}\n\n## Plot of profile\n\n```{r}\n#| message: false\n#| cache: true\nprof <- mev::gev.pll(param = \"Nmean\", dat = ymax, N = 50)\n```\n\n## Confidence intervals\n\nUnder regularity conditions, the likelihood ratio statistic\n\\begin{align*}\n2 \\{\\ell_{\\mathrm{p}}(\\widehat{\\psi}) - \\ell_{\\mathrm{p}}(\\psi_0)\\} \\stackrel{\\cdot}{\\sim} \\chi^2_1\n\\end{align*}\nFor the hypothesis $\\psi = \\psi_0$, a $(1-\\alpha)$ confidence interval based on the profile likelihood ratio test is \n\\begin{align*}\n\\{\\psi: 2\\{\\ell(\\hat{\\theta}) - \\ell(\\hat{\\theta}_{\\psi})\\} \\leq  \\chi^2_1(1-\\alpha)\\}.\n\\end{align*}\n\n```{r}\n(confint(prof))\n```\n\n## Generalized Pareto\n\nIf extremal type theorem applies, then threshold exceedances $Y-u \\mid Y>u$ follow, as $u$ tends to the upper endpoint of $F$, a generalized Pareto distribution.\n\nThe generalized Pareto distribution is\n\\begin{align*}\nH(y; \\tau, \\xi) &= \n\\begin{cases}\n1-\\left(1+\\xi {y}/{\\tau}\\right)_{+}^{-1/\\xi}, & \\xi \\neq 0,\\\\ 1-\n\\exp \\left(-{y}/{\\tau}\\right)_{+},& \\xi = 0, \n\\end{cases} \\label{eq:gpdist}\n\\end{align*}\n\n\n\n## Preprocess data\n\n- Choose a threshold $u$ (either an order statistic or a fixed quantity) and extract exceedances\n- Use @Grimshaw:1993 algorithm to reduce the 2D optimization problem to a line search.\n\n```{r}\nwindlyon <- with(frwind, S2[month(date) <= 4 | month(date) >= 9])\nqulev <- 1-100/nrow(windlyon)\nu <- quantile(windlyon, 1-100/length(windlyon))\n```\n\n## Fitting the generalized Pareto model\n\n```{r}\nopt_gp <- mev::fit.gpd(\n  xdat = windlyon, threshold = u, show = TRUE)\n```\n\n## Modelling bulk\n\nThe generalized Pareto only describes what happens above the threshold, but we can use the empirical distribution below:\n\\begin{align*}\n\\widehat{\\Pr}(Y_i \\le x) = \\sum_{i=1}^n \\mathsf{I}(Y_i \\le x)/n, \\qquad x \\leq u.\n\\end{align*}\n\nMany **splicing models** propose a (semi)parametric model for the bulk; see `evmix` package for examples\n\n## Binomial - generalized Pareto model\n\n- The binomial-generalized Pareto model includes a likelihood contribution for $\\mathsf{I}(Y_i >u) \\sim \\mathsf{Bin}(1, \\zeta_u)$, where $\\zeta_u = \\Pr(Y_i >u)$.\n- This third parameter is orthogonal to the others, and there is a closed-form solution for the MLE. \n\n\n## Block maximum vs threshold exceedances\n\n- Suppose we fit a $\\mathsf{GP}(\\tau, \\xi)$ distribution  to exceedances above $u$.\n- If there are on average $N_y$ observations per year, the distribution of the $N$-year maximum conditional on exceeding $u$ is approximately $H^{\\zeta_uNN_y}$.\n\n\n## Threshold stability\n\nMathematical basis for **extrapolation**.\n\nIf \n\\begin{align*}\nY - u \\mid Y>u \\sim \\mathsf{GP}(\\tau, \\xi),\n\\end{align*}\nthen for $\\{v >u\\in \\mathbb{R}_{+}: \\tau+\\xi (u-v)>0\\}$,  \n\\begin{align*}\nY-v \\mid Y>v \\sim \\mathsf{GP}\\{\\tau + \\xi (u-v), \\xi\\},\n\\end{align*}\nand $\\zeta_v = \\{1+\\xi(v-u)/\\tau\\}^{-1/\\xi}\\zeta_u$.\n\n\n## Threshold stability plots\n\nAssuming data are exactly generalized Pareto, expect shape parameters to be constant (up to sampling variability).\n\n```{r}\n#| eval: false\n#| echo: true\nuseq <- quantile(windlyon, seq(0.9, 0.99, by = 0.01))\ntstab.gpd(windlyon, \n          method = \"profile\",\n          thresh = useq)\n```\n\n---\n\n```{r}\n#| eval: true\n#| echo: false\nuseq <- quantile(windlyon, seq(0.9, 0.99, by = 0.01))\ntstab.gpd(windlyon, \n          method = \"profile\",\n          thresh = useq)\n```\n\n## Inhomogeneous point process\n\nLet $Y_i$ i.i.d. from $F$ with lower endpoint $x^*$. \n\nConsider $a_n>0$ and $b_n \\in \\mathbb{R}$ such that the distribution of the bidimensional point process\n\\begin{align*}\nP_n =\\left\\{ \\frac{i}{n}, \\frac{Y_i-b_n}{a_n}, i = 1, \\ldots, n\\right\\}\n\\end{align*}\nconverges to an inhomogeneous Poisson point process on sets of the form $(a, b) \\times (z, \\infty)$ for $0  \\leq a \\leq b \\leq 1$ and  $z>z_*=\\lim_{n \\to \\infty} \\{(x_*-b_n)/a_n\\}$.\n\n## Intensity of inhomogeneous Poisson process\n\nThe intensity\nmeasure of the limiting point process,  which gives the expected number of points falling in a set is\n\\begin{align*}\n&\\Lambda\\{(a, b) \\times (z, \\infty)\\} \n\\\\&\\quad  = (b-a)\\left(1+ \\xi \\frac{z-\\mu}{\\sigma}\\right)_{+}^{-1/\\xi} \\label{eq:pp_conv}\n\\end{align*}\nfor $\\xi \\neq 0$.\n\n\n## Likelihood of the point process\n\n\\begin{align*}\n\\mathcal{L}(\\boldsymbol{\\theta}; \\boldsymbol{y}) &=  (c\\sigma)^{n_u} \\prod_{i=1}^{n_u} \\left(1+\\xi\\frac{y_i-\\mu}{\\sigma}\\right)^{-1-1/\\xi}_{+} \\\\& \\times \\exp\\left\\{- c \\left(1+ \\xi \\frac{u-\\mu}{\\sigma}\\right)^{-1/\\xi}_{+}\\right\\},\n\\end{align*}\nThe constant $c$ is introduced as a way to relate the parameters of the point process likelihood to those of the GEV fitted to blocks of size $m$ observations, e.g., $c=n/m$. \n\n@Moins:arxiv propose a orthogonal reparametrization.\n\n\n## Link between parametrizations\n\nUnder the  Poisson approximation to the binomial, the expected number of observations above the threshold is\n\\begin{align*}\nc \\left\\{1+ \\xi \\left( \\frac{u-\\mu}{\\sigma}\\right)\\right\\}^{-1/\\xi} \\approx n_u. \\end{align*}\nWe can thus relate $\\mathsf{GP}(\\tau, \\xi)$ with Poisson, where MLE is\n \\begin{align*}\n\\mu_0 & \\approx u - \\sigma_0\\{(n_u/c)^{-\\widehat{\\xi}}-1\\}/\\widehat{\\xi}, \\\\\\sigma_0 &\\approx \\widehat{\\sigma}_u (n_u/c)^{\\widehat{\\xi}}, \\qquad \\xi_0 = \\widehat{\\xi}.\n\\end{align*}\n\n---\n\n```{r}\nu <- quantile(windlyon, 0.99)\nopt.pp <- fit.pp(\n  xdat = windlyon, \n  threshold = u, \n  show = TRUE,\n  np = diff(range(lubridate::year(frwind$date))))\n\n```\n\n\n\n## Return levels\n\n- The probability $p_l$ that a $N$-year return level is exceeded $l$ times in $N$ years of independent annual maxima is $\\mathsf{Bin}(N, 1/N)$.\n- For large $N$, a Poisson approximation yields $p_0=p_1=0.368$, $p_2=0.184$, $p_3=0.061$, etc.\n  - The probability of at least one exceedance over $N$ years is in fact roughly $0.63$.\n  - The return level corresponds to the 0.368 quantile of the $N$-year maximum distribution.\n\n\n\n## References\n\n","srcMarkdownNoYaml":"\n\n\n```{r include=FALSE}\n\nhecbleu <- c(\"#002855\")\nfcols <- c(gris = \"#888b8d\",\n           bleu = \"#0072ce\",\n           aqua = \"#00aec7\",\n           vert = \"#26d07c\",\n           rouge = \"#ff585d\",\n           rose = \"#eb6fbd\",\n           jaune = \"#f3d03e\")\npcols <- c(gris = \"#d9d9d6\",\n           bleu = \"#92c1e9\",\n           agua = \"#88dbdf\",\n           vert = \"#8fe2b0\",\n           rouge = \"#ffb1bb\",\n           rose = \"#eab8e4\",\n           jaune = \"#f2f0a1\")\n\nknitr::opts_chunk$set(fig.retina = 3, collapse = TRUE)\noptions(digits = 3, width = 75)\n```\n\n<!--\n## Plan for today {background-color=\"`r pcols['bleu']`\" .white}\n\n:::: {.columns}\n\n::: {.column width=\"40%\"}\n\n- Univariate extremes\n  - Maximum likelihood\n  - Bayesian\n  - Semiparametric methods\n- Regression models\n\n:::\n\n::: {.column width=\"40%\"}\n\n- Conditional extremes\n- Models for time series\n\n:::\n\n::::\n\n-->\n\n## Extremal type theorem\n\nConsider $Y_i$ $(i=1,2,\\ldots)$ i.i.d. with distribution $F$. \n\nIf there exist normalizing sequences $a_n>0$ and $b_n \\in \\mathbb{R}$ such that\n\\begin{align}\n \\lim_{n \\to \\infty} \\Pr\\left(\\frac{\\max_{i=1}^n Y_i - b_n}{a_n} \\leq x \\right) = G(x),\n\\label{eq:gevconv}\n\\end{align}\nfor $G$ a non-degenerate distribution, then $G$ must be **generalized extreme value** (GEV).\n\n## Generalized extreme value distribution\nWith location $\\mu \\in \\mathbb{R}$, scale $\\sigma \\in \\mathbb{R}_{+}$ and shape $\\xi \\in \\mathbb{R}$ parameters, the distribution function is\n\\begin{align*}\nG(x) =\\begin{cases}\n \\exp\\left\\{-\\left(1+\\xi \\frac{x-\\mu}{\\sigma}\\right)^{-1/\\xi}_{+}\\right\\}, & \\xi \\neq 0;\\\\\n\\exp\\left\\{-\\exp\\left(-\\frac{x-\\mu}{\\sigma}\\right)\\right\\}, & \\xi = 0,\n\\end{cases}\n\\end{align*}\nwhere $x_{+} = \\max\\{x, 0\\}$.\n\nThe support is $\\{x \\in \\mathbb{R}: \\xi(x-\\mu)/\\sigma > -1\\}$.\n\n## Max-stability property\n\nIf $Y_i \\sim \\mathsf{GEV}(\\mu, \\sigma, \\xi)$ are independent, then $$\\max_{i=1}^N Y_i \\sim \\mathsf{GEV}(\\mu_N, \\sigma_N, \\xi),$$ where\n\n- $\\mu_N = \\mu + \\sigma(N^\\xi-1)/\\xi$\n- $\\sigma_N = \\sigma N^\\xi$\n\n(case $\\xi=0$ defined by continuity).\n\n\n\n\n\n## Block maximum\n\nWe can \n\n- partition data into blocks of roughly equal size $m$ and \n- fit a GEV distribution to the maximum of the blocks.\n\n```{r}\n#| eval: true\n#| echo: true \nlibrary(mev)\nlibrary(xts)\nlibrary(lubridate)\ndata(frwinds, package = \"mev\")\nlyon <- with(frwind, \n             xts(x = S2, order.by = date))\n# Create series of yearly maximum\nymax <- apply.yearly(lyon, max)\n```\n\n## Basics of likelihoods\n\n- Denote by $\\boldsymbol{\\theta} \\in \\mathcal{S} \\subseteq \\mathbb{R}^p$ the parameter vector.\n- Assume data has joint density $f(\\boldsymbol{y}; \\boldsymbol{\\theta})$.\n- The log likelihood is $\\ell(\\boldsymbol{\\theta}) = \\log f(\\boldsymbol{y}; \\boldsymbol{\\theta})$.\n- If the $n$ observations are independent with density or mass function $f_i$, then $\\ell(\\boldsymbol{\\theta}) = \\sum_{i=1}^n \\log f_i(y_i; \\boldsymbol{\\theta})$.\n- The maximum likelihood estimate $\\widehat{\\boldsymbol{\\theta}}$ is found by maximizing (numerically) $\\ell(\\boldsymbol{\\theta})$.\n\n---\n\n\n\n## Fitting GEV using `mev` package\n\n```{r}\n#| eval: true\n#| echo: true\nopt_gev <- mev::fit.gev(xdat = ymax, show = TRUE)\nmle <- coef(opt_gev)\n```\n\n## Goodness-of-fit diagnostics\n\nCustom methods (`print`, `plot`, `coef`, etc.) are defined\n\n```{r}\nmethods(class = \"mev_gev\")\npar(mfrow = c(1,2))\nplot(opt_gev)\n```\n\n\n## Numerical tricks\n\n- Standardize observations (e.g., `scale`) to facilitate optimization --- the GEV is a location-scale family.\n- Even if the limit is continuous and well defined at $\\xi=0$, the log likelihood and it's derivatives involves terms of the form $\\log(1+\\xi x)$, which are numerically unstable when $\\xi \\to 0$.\n  - Pro tip: do not code the likelihood yourself! Otherwise,\n    - use high precision arithmetic, e.g., `log1p`\n    - replace the terms that blow up by Taylor series expansion near $\\xi=0$ (interpolation).\n\n## Why use maximum likelihood?\n\n- Easy to generalize to complex settings (nonstationarity, regression models, censoring, rounding, etc.)\n- Known to be asymptotically most efficient (Cramér-Rao bound), even if they can be biased.\n- Point estimators, etc. are invariant to reparametrization.\n\n## Invariance property of maximum likelihood\n\nIf $h$ is a mapping, then $h(\\widehat{\\boldsymbol{\\theta}})$ is the MLE of $h(\\boldsymbol{\\theta})$.\n\nThe expected value of the $N=50$-years maximum for $\\xi < 1$, is  \\begin{align*}\\mathfrak{e}_N = h(\\mu, \\sigma, \\xi) = \\mu_N + \\sigma_N\\{\\Gamma(1-\\xi)-1\\}/\\xi.\n\\end{align*}\n\n\nThus, the MLE $\\widehat{\\mathfrak{e}}_N=h(\\widehat{\\mu}, \\widehat{\\sigma}, \\widehat{\\xi})$.\n\n```{r}\n# MLE of expectation of maximum of 50 blocks\ngev.mle(xdat = ymax, args = \"Nmean\", N = 50)\n```\n\n\n\n\n## Score vector\n\nWhen the log likelihood is differentiable, the MLE is the root of the score equation, meaning $\\ell_{\\boldsymbol{\\theta}}(\\widehat{\\boldsymbol{\\theta}}) = \\partial \\ell(\\boldsymbol{\\theta}) / \\partial \\boldsymbol{\\theta} = \\boldsymbol{0}_p$.\n\n\n```{r}\n#| eval: true\n#| echo: true\nmev::gev.score(par = mle, dat = ymax) # score\n```\n\n- Gradient-based algorithms exploit this feature for  optimization\n- but beware of support constraints!\n\nBest to reparametrize so that the parameter space is $\\mathbb{R}^p$ if possible.\n\n\n## Information matrix and standard errors\n\nWe can extract standard errors by taking the square root of the diagonal elements of the inverse of either\n\n- the Fisher information, $\\imath(\\boldsymbol{\\theta}) = \\mathsf{Cov}\\{\\ell_{\\boldsymbol{\\theta}}(\\boldsymbol{\\theta})\\}$ or\n- the observed information $\\jmath(\\boldsymbol{\\theta}) = - \\partial^2 \\ell(\\boldsymbol{\\theta})/ \\partial \\boldsymbol{\\theta} \\partial \\boldsymbol{\\theta}^\\top$,\n\nboth evaluated at the MLE $\\widehat{\\boldsymbol{\\theta}}$.\n\n\n```{r}\n#| eval: true\n#| echo: true\n# Compute observed information matrix\njmat <- mev::gev.infomat(par = mle, dat = ymax)\n# Compute standard errors\nsqrt(diag(solve(jmat)))\n# Compare with opt$std.err\n```\n\n## Some remarks\n\nWe may compute $j(\\widehat{\\boldsymbol{\\theta}})$ (the negative Hessian of log likelihood) numerically through finite differences.\n\nMany software implementations compute MLE via Nelder--Mead simplex algorithm: \n\n- check the gradient and/or\n- the log likelihood differences\n\nto make sure the optimisation was successful.\n\n## Properties of MLE\n\n\n- Maximum likelihood estimators are asymptotically Gaussian whenever $\\xi > -1/2$ with data in domain of attraction of extreme value distribution.\n- Consistency requires that one increases block size, etc. as $n$ increases at a particular rate depending on $F$.\n\n\n\n## Regularity conditions\n\nSome cumulants (moments of derivatives of the log likelihood) of extreme value models do not exist.\n\n- the MLE does not solve the score equation if $\\widehat{\\xi} \\leq -1$\n- MLE is not unique for $\\xi < -1$ (some combinations of $\\mu$ and $\\sigma$ yield infinite log likelihood). \n   - restrict the parameter space to $\\{\\boldsymbol{\\theta}: y_1, \\ldots, y_n \\in \\mathrm{supp}(\\boldsymbol{\\theta}), \\xi \\geq -1\\}$\n   - For GEV, MLE at boundary is $(\\widehat{\\mu}=\\overline{y}, \\widehat{\\sigma} = \\max(y) - \\overline{y}, \\xi=-1)$.\n\n## Regularity conditions\n\n   \nIf $\\widehat{\\xi} < -1/2$, cannot evaluate the information matrix.\n\n- Regularity assumptions do not apply! reported  std. errors are misleading.\n- Typically faster convergence, joint limit not asymptotically normal [@Smith:1985].\n\nIn applications, shape is typically close to zero, so authors sometimes restrict $\\xi \\in (-0.5, 0.5)$. \n\nPenalization of the shape helps ensure that we get reasonable estimates in small samples.\n\n## Profile log likelihood\n\nConsider a functional of interest $\\psi$ and other parameters $\\boldsymbol{\\lambda}$, treated as nuisance.\n\nWe reparametrize the log likelihood in terms of $(\\psi, \\boldsymbol{\\lambda})$ and compute  the profile log likelihood\n\\begin{align*}\n\\ell_{\\mathrm{p}}(\\psi) = \\max_{\\boldsymbol{\\lambda}} \\ell(\\psi, \\boldsymbol{\\lambda})\n\\end{align*}\n\n## Plot of profile\n\n```{r}\n#| message: false\n#| cache: true\nprof <- mev::gev.pll(param = \"Nmean\", dat = ymax, N = 50)\n```\n\n## Confidence intervals\n\nUnder regularity conditions, the likelihood ratio statistic\n\\begin{align*}\n2 \\{\\ell_{\\mathrm{p}}(\\widehat{\\psi}) - \\ell_{\\mathrm{p}}(\\psi_0)\\} \\stackrel{\\cdot}{\\sim} \\chi^2_1\n\\end{align*}\nFor the hypothesis $\\psi = \\psi_0$, a $(1-\\alpha)$ confidence interval based on the profile likelihood ratio test is \n\\begin{align*}\n\\{\\psi: 2\\{\\ell(\\hat{\\theta}) - \\ell(\\hat{\\theta}_{\\psi})\\} \\leq  \\chi^2_1(1-\\alpha)\\}.\n\\end{align*}\n\n```{r}\n(confint(prof))\n```\n\n## Generalized Pareto\n\nIf extremal type theorem applies, then threshold exceedances $Y-u \\mid Y>u$ follow, as $u$ tends to the upper endpoint of $F$, a generalized Pareto distribution.\n\nThe generalized Pareto distribution is\n\\begin{align*}\nH(y; \\tau, \\xi) &= \n\\begin{cases}\n1-\\left(1+\\xi {y}/{\\tau}\\right)_{+}^{-1/\\xi}, & \\xi \\neq 0,\\\\ 1-\n\\exp \\left(-{y}/{\\tau}\\right)_{+},& \\xi = 0, \n\\end{cases} \\label{eq:gpdist}\n\\end{align*}\n\n\n\n## Preprocess data\n\n- Choose a threshold $u$ (either an order statistic or a fixed quantity) and extract exceedances\n- Use @Grimshaw:1993 algorithm to reduce the 2D optimization problem to a line search.\n\n```{r}\nwindlyon <- with(frwind, S2[month(date) <= 4 | month(date) >= 9])\nqulev <- 1-100/nrow(windlyon)\nu <- quantile(windlyon, 1-100/length(windlyon))\n```\n\n## Fitting the generalized Pareto model\n\n```{r}\nopt_gp <- mev::fit.gpd(\n  xdat = windlyon, threshold = u, show = TRUE)\n```\n\n## Modelling bulk\n\nThe generalized Pareto only describes what happens above the threshold, but we can use the empirical distribution below:\n\\begin{align*}\n\\widehat{\\Pr}(Y_i \\le x) = \\sum_{i=1}^n \\mathsf{I}(Y_i \\le x)/n, \\qquad x \\leq u.\n\\end{align*}\n\nMany **splicing models** propose a (semi)parametric model for the bulk; see `evmix` package for examples\n\n## Binomial - generalized Pareto model\n\n- The binomial-generalized Pareto model includes a likelihood contribution for $\\mathsf{I}(Y_i >u) \\sim \\mathsf{Bin}(1, \\zeta_u)$, where $\\zeta_u = \\Pr(Y_i >u)$.\n- This third parameter is orthogonal to the others, and there is a closed-form solution for the MLE. \n\n\n## Block maximum vs threshold exceedances\n\n- Suppose we fit a $\\mathsf{GP}(\\tau, \\xi)$ distribution  to exceedances above $u$.\n- If there are on average $N_y$ observations per year, the distribution of the $N$-year maximum conditional on exceeding $u$ is approximately $H^{\\zeta_uNN_y}$.\n\n\n## Threshold stability\n\nMathematical basis for **extrapolation**.\n\nIf \n\\begin{align*}\nY - u \\mid Y>u \\sim \\mathsf{GP}(\\tau, \\xi),\n\\end{align*}\nthen for $\\{v >u\\in \\mathbb{R}_{+}: \\tau+\\xi (u-v)>0\\}$,  \n\\begin{align*}\nY-v \\mid Y>v \\sim \\mathsf{GP}\\{\\tau + \\xi (u-v), \\xi\\},\n\\end{align*}\nand $\\zeta_v = \\{1+\\xi(v-u)/\\tau\\}^{-1/\\xi}\\zeta_u$.\n\n\n## Threshold stability plots\n\nAssuming data are exactly generalized Pareto, expect shape parameters to be constant (up to sampling variability).\n\n```{r}\n#| eval: false\n#| echo: true\nuseq <- quantile(windlyon, seq(0.9, 0.99, by = 0.01))\ntstab.gpd(windlyon, \n          method = \"profile\",\n          thresh = useq)\n```\n\n---\n\n```{r}\n#| eval: true\n#| echo: false\nuseq <- quantile(windlyon, seq(0.9, 0.99, by = 0.01))\ntstab.gpd(windlyon, \n          method = \"profile\",\n          thresh = useq)\n```\n\n## Inhomogeneous point process\n\nLet $Y_i$ i.i.d. from $F$ with lower endpoint $x^*$. \n\nConsider $a_n>0$ and $b_n \\in \\mathbb{R}$ such that the distribution of the bidimensional point process\n\\begin{align*}\nP_n =\\left\\{ \\frac{i}{n}, \\frac{Y_i-b_n}{a_n}, i = 1, \\ldots, n\\right\\}\n\\end{align*}\nconverges to an inhomogeneous Poisson point process on sets of the form $(a, b) \\times (z, \\infty)$ for $0  \\leq a \\leq b \\leq 1$ and  $z>z_*=\\lim_{n \\to \\infty} \\{(x_*-b_n)/a_n\\}$.\n\n## Intensity of inhomogeneous Poisson process\n\nThe intensity\nmeasure of the limiting point process,  which gives the expected number of points falling in a set is\n\\begin{align*}\n&\\Lambda\\{(a, b) \\times (z, \\infty)\\} \n\\\\&\\quad  = (b-a)\\left(1+ \\xi \\frac{z-\\mu}{\\sigma}\\right)_{+}^{-1/\\xi} \\label{eq:pp_conv}\n\\end{align*}\nfor $\\xi \\neq 0$.\n\n\n## Likelihood of the point process\n\n\\begin{align*}\n\\mathcal{L}(\\boldsymbol{\\theta}; \\boldsymbol{y}) &=  (c\\sigma)^{n_u} \\prod_{i=1}^{n_u} \\left(1+\\xi\\frac{y_i-\\mu}{\\sigma}\\right)^{-1-1/\\xi}_{+} \\\\& \\times \\exp\\left\\{- c \\left(1+ \\xi \\frac{u-\\mu}{\\sigma}\\right)^{-1/\\xi}_{+}\\right\\},\n\\end{align*}\nThe constant $c$ is introduced as a way to relate the parameters of the point process likelihood to those of the GEV fitted to blocks of size $m$ observations, e.g., $c=n/m$. \n\n@Moins:arxiv propose a orthogonal reparametrization.\n\n\n## Link between parametrizations\n\nUnder the  Poisson approximation to the binomial, the expected number of observations above the threshold is\n\\begin{align*}\nc \\left\\{1+ \\xi \\left( \\frac{u-\\mu}{\\sigma}\\right)\\right\\}^{-1/\\xi} \\approx n_u. \\end{align*}\nWe can thus relate $\\mathsf{GP}(\\tau, \\xi)$ with Poisson, where MLE is\n \\begin{align*}\n\\mu_0 & \\approx u - \\sigma_0\\{(n_u/c)^{-\\widehat{\\xi}}-1\\}/\\widehat{\\xi}, \\\\\\sigma_0 &\\approx \\widehat{\\sigma}_u (n_u/c)^{\\widehat{\\xi}}, \\qquad \\xi_0 = \\widehat{\\xi}.\n\\end{align*}\n\n---\n\n```{r}\nu <- quantile(windlyon, 0.99)\nopt.pp <- fit.pp(\n  xdat = windlyon, \n  threshold = u, \n  show = TRUE,\n  np = diff(range(lubridate::year(frwind$date))))\n\n```\n\n\n\n## Return levels\n\n- The probability $p_l$ that a $N$-year return level is exceeded $l$ times in $N$ years of independent annual maxima is $\\mathsf{Bin}(N, 1/N)$.\n- For large $N$, a Poisson approximation yields $p_0=p_1=0.368$, $p_2=0.184$, $p_3=0.061$, etc.\n  - The probability of at least one exceedance over $N$ years is in fact roughly $0.63$.\n  - The return level corresponds to the 0.368 quantile of the $N$-year maximum distribution.\n\n\n\n## References\n\n"},"formats":{"revealjs":{"identifier":{"display-name":"RevealJS","target-format":"revealjs","base-format":"revealjs"},"execute":{"fig-width":10,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","html-math-method":{"method":"mathjax","url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML-full"},"slide-level":2,"to":"revealjs","output-file":"EVA2023-Rsoftware-likelihood.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":false,"quarto-version":"1.3.361","auto-stretch":true,"url":"https://lbelzile.github.io/EVA2023-tutorial","bibliography":["../files/bib/vignette.bib","EVA2023-software.bib"],"csl":"../files/bib/apa.csl","title":"Tutorial on Statistical Computing for Extremes with **R**","author":"Léo Belzile","subtitle":"Likelihood-based inference for univariate extremes","date":"June 30, 2023","slideNumber":true,"previewLinks":"auto","theme":["simple","hecmontreal.scss"],"title-slide-attributes":{"data-background-color":"#002855"}}}},"projectFormats":["html"]}
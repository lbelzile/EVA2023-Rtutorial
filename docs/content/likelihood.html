<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.361">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Tutorial on Statistical Computing on Extremes with R - Likelihood-based inference</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Tutorial on Statistical Computing on Extremes with R</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-notes" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Notes</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-notes">    
        <li>
    <a class="dropdown-item" href="../content/likelihood.html" rel="" target="">
 <span class="dropdown-text">1: Likelihood-based inference</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../content/bayesian.html" rel="" target="">
 <span class="dropdown-text">2: Bayesian modelling</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../content/semiparametric.html" rel="" target="">
 <span class="dropdown-text">3: Semiparametric modelling</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../content/regression.html" rel="" target="">
 <span class="dropdown-text">4: Nonstationary regression models</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://lbelzile.github.io/texmexIntro/" rel="" target="">
 <span class="dropdown-text">5: Conditional extremes</span></a>
  </li>  
    </ul>
  </li>
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content column-page" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Likelihood-based inference</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p>The <code>mev</code> package provides gradient-based optimization routines for fitting univariate extreme value models, either block maxima or threshold exceedances, using one of four likelihoods: that of the generalized extreme value distribution, the generalized Pareto distribution, and the inhomogeneous Poisson point process and the <span class="math inline">\(r\)</span>-largest order statistics.</p>
<p>Relative to other packages such as <code>evd</code> or <code>ismev</code>, the package functions include analytic expressions for the score and observed informations, with careful interpolation when <span class="math inline">\(\xi \approx 0\)</span>. However, <code>mev</code> does not handle generalized linear or generalized additive models for the parameters, to avoid having as many inequality constraints in the optimization as there are observations times the number of covariates.</p>
<section id="basic-theory" class="level2">
<h2 class="anchored" data-anchor-id="basic-theory">Basic theory</h2>
<p>Let <span class="math inline">\(\ell(\boldsymbol{y}; \boldsymbol{\theta})\)</span> denotes the log-likelihood of an <span class="math inline">\(n\)</span> sample with a <span class="math inline">\(p\)</span>-dimensional parameter <span class="math inline">\(\boldsymbol{\theta}\)</span>. The score vector is <span class="math inline">\(\ell_{\boldsymbol{\theta}}(\boldsymbol{\theta})=\partial \ell / \partial \boldsymbol{\theta}\)</span>, while the Fisher information is <span class="math inline">\(\imath(\boldsymbol{\theta})=\mathrm{E}\{\ell_{\boldsymbol{\theta}}(\boldsymbol{\theta})\ell_{\boldsymbol{\theta}}(\boldsymbol{\theta})^\top\}\)</span>. Under regularity conditions, we also have <span class="math inline">\(\imath(\boldsymbol{\theta}) = - \mathrm{E}(\partial^2 \ell / \partial \boldsymbol{\theta}\partial \boldsymbol{\theta}^\top)\)</span>. The observed information is the negative Hessian <span class="math inline">\(\jmath(\boldsymbol{\theta})-\partial^2 \ell / \partial \boldsymbol{\theta}\partial \boldsymbol{\theta}^\top\)</span>, evaluated at the maximum likelihood estimator <span class="math inline">\(\hat{\boldsymbol{\theta}}\)</span>.</p>
<p>By definition, the maximum likelihood estimator solves the score equation, i.e.&nbsp;<span class="math inline">\(\ell_{\boldsymbol{\theta}}(\hat{\boldsymbol{\theta}})=\boldsymbol{0}_p\)</span>. If the maximum likelihood estimator is not available in closed-form, its solution is found numerically and this property can be used to verify that the optimization routine has converged or for gradient-based maximization algorithms.</p>
</section>
<section id="statistical-inference" class="level2">
<h2 class="anchored" data-anchor-id="statistical-inference">Statistical inference</h2>
<p>This section presents some test statistics that can easily be computed using some of the functionalities of <code>mev</code>, as well as confidence intervals for parameters and common functionals, based on the profile likelihood.</p>
<p>The three main type of test statistics for likelihood-based inference are the Wald, score and likelihood ratio tests. The three main classes of statistics for testing a simple null hypothesis <span class="math inline">\(\mathscr{H}_0: \boldsymbol{\theta}=\boldsymbol{\theta}_0\)</span> against the alternative <span class="math inline">\(\mathscr{H}_a: \boldsymbol{\theta} \neq \boldsymbol{\theta}_0\)</span> are the likelihood ratio, the score and the Wald statistics, defined respectively as <span class="math display">\[\begin{align*}
w &amp;= 2 \left\{ \ell(\hat{\boldsymbol{\theta}})-\ell(\boldsymbol{\theta}_0)\right\},\qquad
\\w_{\mathsf{score}} &amp;= U^\top(\boldsymbol{\theta}_0)i^{-1}(\boldsymbol{\theta}_0)\ell_{\boldsymbol{   heta}}(\boldsymbol{\theta}_0),\qquad
\\ w_{\mathsf{wald}} &amp;= (\hat{\boldsymbol{\theta}}-\boldsymbol{\theta}_0)^\top i(\boldsymbol{\theta}_0)(\hat{\boldsymbol{\theta}}-\boldsymbol{\theta}_0),
\end{align*}\]</span> where <span class="math inline">\(\hat{\boldsymbol{\theta}}\)</span> is the maximum likelihood estimate under the alternative and <span class="math inline">\(\boldsymbol{\theta}_0\)</span> is the null value of the parameter vector. The statistics <span class="math inline">\(w, w_{\mathsf{score}}, w_{\mathsf{wald}}\)</span> are all first order equivalent and asymptotically follow a <span class="math inline">\(\chi^2_p\)</span> distribution, where <span class="math inline">\(q\)</span> is the difference between <span class="math inline">\(p\)</span> and the number of parameters under the null hypothesis. Under the conditions of the Neyman–Pearson theorem, the likelihood ratio test is most powerful test of the lot. The score statistic <span class="math inline">\(w_{\mathsf{score}}\)</span> only requires calculation of the score and information under <span class="math inline">\(\mathscr{H}_0\)</span>, which can be useful in problems where calculations under the alternative are difficult to obtain. The Wald statistic <span class="math inline">\(w_{\mathsf{wald}}\)</span> is not parametrization-invariant and typically has poor coverage properties.</p>
<p>Oftentimes, we are interested in a functional of the parameter vector <span class="math inline">\(\boldsymbol{\theta}\)</span>. The profile likelihood <span class="math inline">\(\ell_\mathsf{p}\)</span>, a function of <span class="math inline">\(\boldsymbol{\psi}\)</span> alone, is obtained by maximizing the likelihood pointwise at each fixed value <span class="math inline">\(\boldsymbol{\psi}=\boldsymbol{\psi}_0\)</span> over the nuisance vector <span class="math inline">\(\boldsymbol{\lambda}_{\psi_0}\)</span>, <span class="math display">\[\begin{align*}
   \ell_\mathsf{p}(\boldsymbol{\psi})=\max_{\boldsymbol{\lambda}}\ell(\boldsymbol{\psi}, \boldsymbol{\lambda})=\ell(\boldsymbol{\psi}, \hat{\boldsymbol{\lambda}}_{\boldsymbol{\psi}}).
\end{align*}\]</span> We denote the restricted maximum likelihood estimator <span class="math inline">\(\hat{\boldsymbol{\theta}}_\psi= (\psi, \hat{\lambda}_{\psi})\)</span>.</p>
<p>We can define score and information in the usual fashion: for example, the observed profile information function is [j_() =- = {j^{}(, _{})}^{-1}. ]</p>
<p>We can turn tests and their asymptotic distribution into confidence intervals. For the hypothesis <span class="math inline">\(\psi = \psi_0\)</span>, a <span class="math inline">\((1-\alpha)\)</span> confidence interval based on the profile likelihood ratio test is <span class="math inline">\(\{ \psi: 2\{\ell(\hat{\theta}) - \ell(\hat{\theta}_{\psi})\} \leq \chi^2_1(0.95)\}\)</span>.</p>
<section id="likelihoods" class="level3">
<h3 class="anchored" data-anchor-id="likelihoods">Likelihoods</h3>
<p>There are four basic likelihoods for univariate extremes: the likelihood of the generalized extreme value (GEV) distribution for block maxima, the likelihood for the generalized Pareto distribution and that of the non-homogeneous Poisson process (NHPP) for exceedances above a threshold <span class="math inline">\(u\)</span> and lastly the likelihood of the <span class="math inline">\(r\)</span>-largest observations.</p>
</section>
<section id="generalized-extreme-value-distribution" class="level3">
<h3 class="anchored" data-anchor-id="generalized-extreme-value-distribution">Generalized extreme value distribution</h3>
<p>The generalized extreme value (GEV) distribution with location parameter <span class="math inline">\(\mu \in \mathbb{R}\)</span>, scale parameter <span class="math inline">\(\sigma \in \mathbb{R}_{+}\)</span> and shape parameter <span class="math inline">\(\xi \in \mathbb{R}\)</span> is <span class="math display">\[\begin{align*}
  G(x)  =
\begin{cases}
\exp\left\{-\left(1+\xi \frac{x-\mu}{\sigma}\right)^{-1/\xi}\right\}, &amp;  \xi \neq 0,\\
\exp \left\{ -\exp \left(-\frac{x-\mu}{\sigma}\right)\right\},&amp;  \xi = 0,
\end{cases}
\end{align*}\]</span> defined on <span class="math inline">\(\{x \in \mathbb{R}: \xi(x-\mu)/\sigma &gt; -1\}\)</span> where <span class="math inline">\(x_{+} = \max\{0, x\}\)</span>. The case <span class="math inline">\(\xi=0\)</span> is commonly known as the Gumbel distribution. We denote the distribution by <span class="math inline">\(\mathsf{GEV}(\mu, \sigma, \xi)\)</span>.</p>
<p>The max-stability property allows one to extrapolate the distribution beyond observed levels: one can show that the distribution of the maximum of a larger block (or <span class="math inline">\(N\)</span> block maximum) would be also generalized extreme value if <span class="math inline">\(Y_i \sim \mathsf{GEV}(\mu, \sigma, \xi)\)</span> are independent, where <span class="math inline">\(\max_{i=1}^N Y_i \sim \mathsf{GEV}(\mu_N, \sigma_N, \xi)\)</span> and <span class="math inline">\(\mu_N = \mu + \sigma(N^\xi-1)/\xi\)</span> and <span class="math inline">\(\sigma_N = \sigma N^\xi, \xi_N = \xi)\)</span> — the case <span class="math inline">\(\xi=0\)</span> is defined by continuity. In practice, we can partition data into <span class="math inline">\(m\)</span> blocks of roughly equal size <span class="math inline">\(n/m\)</span> and fit a GEV distribution to the maximum of the blocks.</p>
<p>The GEV distribution is suitable for maximum of a large number of observations: the larger the block size, the closer the approximation will be, but the smaller the sample size <span class="math inline">\(m\)</span>.in In practice, there is a natural block size (say yearly) over which to compute maximum. The advantage is that, even if data are not stationary, we can expect the maximum to occur roughly at the same time of the year (e.g., for temperature) and so even if the true block size is much lower than 365 days, we can still use our approach.</p>
<p>The <code>fit.gev</code> function includes two optimization routines: either use the PORT methods from <code>nlminb</code>, or Broyden-Fletcher-Goldfarb-Shanno algorithm (<code>BFGS</code>) inside a constrained optimization algorithm (augmented Lagrangian). The default option is <code>nlminb</code>, which sometimes returns diagnostics indicating false convergence when the model is near the maximum likelihood estimate.</p>
<p>As for other model, parameters can be fixed and nested models can be compared using the <code>anova</code> S3 method. For these, we distinguish between estimated coefficients (<code>estimate</code>) or with the <code>coef</code> method, and the full vector of parameters, <code>param</code>.</p>
</section>
<section id="numerical-example" class="level3">
<h3 class="anchored" data-anchor-id="numerical-example">Numerical example</h3>
<p>We consider in the tutorial daily mean wind speed data, measured in km/h, at four weather stations located in the south of France. We first take the data for Lyon’s airport (station <span class="math inline">\(S_2\)</span>) and compute the annual maximum.</p>
<div class="cell" data-hash="likelihood_cache/html/unnamed-chunk-1_7cc7c227102fc34005bd1e884779bf3e">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mev)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co"># library(xts)</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co"># library(lubridate)</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(frwind, <span class="at">package =</span> <span class="st">"mev"</span>)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>lyon <span class="ot">&lt;-</span> <span class="fu">with</span>(frwind,</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>             xts<span class="sc">::</span><span class="fu">xts</span>(<span class="at">x =</span> S2, <span class="at">order.by =</span> date))</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Create series of yearly maximum</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>ymax <span class="ot">&lt;-</span> xts<span class="sc">::</span><span class="fu">apply.yearly</span>(lyon, max)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can then fit a GEV distribution via maximum likelihood to the yearly maximum, extract the coefficients <span class="math inline">\(\widehat{\boldsymbol{\theta}}\)</span> and check convergence by computing the score <span class="math inline">\(\ell_{\boldsymbol{\theta}}(\widehat{\boldsymbol{\theta}})\)</span> and comparing it to the zero vector.</p>
<div class="cell" data-hash="likelihood_cache/html/unnamed-chunk-2_615ec3fd6d47d80970eabcf45203b2c2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>opt_gev <span class="ot">&lt;-</span> mev<span class="sc">::</span><span class="fu">fit.gev</span>(<span class="at">xdat =</span> ymax, <span class="at">show =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Log-likelihood: -141.6626 

Estimates
     loc     scale     shape  
36.18449   3.94287  -0.01124  

Standard Errors
   loc   scale   shape  
0.6589  0.4881  0.1318  

Optimization Information
  Convergence: successful 
  Function Evaluations: 27 
  Gradient Evaluations: 11 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>mle <span class="ot">&lt;-</span> <span class="fu">coef</span>(opt_gev)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="fu">isTRUE</span>(<span class="fu">all.equal</span>(<span class="fu">rep</span>(<span class="dv">0</span>,<span class="dv">3</span>),</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>                 mev<span class="sc">::</span><span class="fu">gev.score</span>(<span class="at">par =</span> mle, <span class="at">dat =</span> ymax),</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>                 <span class="at">check.attributes =</span> <span class="cn">FALSE</span>,</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>                 <span class="at">tolerance =</span> <span class="fl">1e-5</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] TRUE</code></pre>
</div>
</div>
<p>Having found the MLE, we can compute the covariance matrix of the parameters from the observed information matrix. The standard errors are the square root of the elements on the diagonal. While <code>mev</code> uses exact formulae, these can be approximated by computing the hessian via finite differences.</p>
<div class="cell" data-hash="likelihood_cache/html/unnamed-chunk-3_70797374f7e53c40f29baeb8204155d2">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute observed information matrix</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>jmat <span class="ot">&lt;-</span> mev<span class="sc">::</span><span class="fu">gev.infomat</span>(<span class="at">par =</span> mle, <span class="at">dat =</span> ymax)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute standard errors</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>se_mle <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">diag</span>(<span class="fu">solve</span>(jmat)))</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare with 'mev' output</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="fu">isTRUE</span>(<span class="fu">all.equal</span>(se_mle, opt_gev<span class="sc">$</span>std.err))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] TRUE</code></pre>
</div>
</div>
<p>Even if we have parameter estimates, there is no guarantee that the model is adequate. Standard visual goodness-of-fit diagnostics can be obtained with the <code>plot</code> method. To see other methods, query <code>methods(class = "mev_gev")</code>.</p>
<div class="cell" data-hash="likelihood_cache/html/unnamed-chunk-4_5c1c0c739680a2d59d1a2bef4884f20c">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># PP and QQ plots</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(opt_gev)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="likelihood_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid" width="672"></p>
</div>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">graphics.off</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The Gumbel distribution, which corresponds to a GEV with shape <span class="math inline">\(\xi=0\)</span>, can be estimated by restricting a parameter. We then do a likelihood ratio test since models are nested.</p>
<div class="cell" data-hash="likelihood_cache/html/unnamed-chunk-5_a644718169c55ca68a4953751948a25b">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>opt_gumb <span class="ot">&lt;-</span> mev<span class="sc">::</span><span class="fu">fit.gev</span>(<span class="at">xdat =</span> ymax,</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>                         <span class="at">fpar =</span> <span class="fu">list</span>(<span class="at">shape =</span> <span class="dv">0</span>))</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(opt_gev, opt_gumb)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Deviance Table

         npar Deviance Df  Chisq Pr(&gt;Chisq)
opt_gev     3   283.32                     
opt_gumb    2   283.33  1 0.0073     0.9321</code></pre>
</div>
</div>
<p>None of the parameters are of interest in themselves. We may be interested rather by a risk summary, which is a function of parameters. For example, we could get the parameters of the GEV for 50 years via max-stability and return the average if <span class="math inline">\(\widehat{\xi}&lt;1\)</span>, or quantiles — the most popular choices are the median and 0.368, which corresponds roughly to the 50 year return level for threshold exceedances.</p>
<p>All of these are invariant to reparametrization, so we can use the formula and plug-in the parameter values. For inference, we reparametrize the model in terms of this quantity, then vary over a grid of values of the 50-year average maximum and compute profile-likelihood-based confidence intervals at level 95%.</p>
<div class="cell" data-hash="likelihood_cache/html/unnamed-chunk-6_bef02d849ae3765d5c037db0b60adc37">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="fu">gev.mle</span>(<span class="at">xdat =</span> ymax, <span class="at">args =</span> <span class="st">"Nmean"</span>, <span class="at">N =</span> <span class="dv">50</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  Nmean 
53.4114 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute profile log-likelihood</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>prof <span class="ot">&lt;-</span> mev<span class="sc">::</span><span class="fu">gev.pll</span>(<span class="at">param =</span> <span class="st">"Nmean"</span>, <span class="at">dat =</span> ymax, <span class="at">N =</span> <span class="dv">50</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="likelihood_files/figure-html/unnamed-chunk-6-1.png" class="img-fluid" width="672"></p>
</div>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract confidence intervals</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>(<span class="fu">confint</span>(prof))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Estimate Lower CI Upper CI 
53.41140 47.79346 73.63881 </code></pre>
</div>
</div>
</section>
<section id="generalized-pareto-distribution" class="level3">
<h3 class="anchored" data-anchor-id="generalized-pareto-distribution">Generalized Pareto distribution</h3>
<p>The generalized Pareto (GP) distribution with scale <span class="math inline">\(\sigma \in \mathbb{R}_{+}\)</span> and shape <span class="math inline">\(\xi \in \mathbb{R}\)</span> is <span class="math display">\[\begin{align*}
  G(x)  =
\begin{cases}
1-\left(1+\xi \frac{x}{\sigma}\right)_{+}^{-1/\xi}, &amp;  \xi \neq 0,\\ 1-
\exp \left(-\frac{x}{\sigma}\right),&amp;  \xi = 0.
\end{cases}
\end{align*}\]</span> The range of the generalized Pareto distribution is <span class="math inline">\([0, -\sigma/\xi)\)</span> if <span class="math inline">\(\xi &lt; 0\)</span> and is <span class="math inline">\(\mathbb{R}_{+}\)</span> otherwise. We denote the distribution by <span class="math inline">\(\mathsf{GP}(\sigma, \xi)\)</span>. The default optimization algorithm for this model is that of <span class="citation" data-cites="Grimshaw:1993">Grimshaw (<a href="#ref-Grimshaw:1993" role="doc-biblioref">1993</a>)</span>, which reduces the dimension of the optimization through profiling. The exponential distribution and the case <span class="math inline">\(\xi=-1\)</span> are handled separately. If the sample coefficient of variation is less than one, the global maximum lies on the boundary of the parameter space since there exists for any <span class="math inline">\(\xi&lt;-1\)</span> a value <span class="math inline">\(\sigma^*\)</span> such that <span class="math inline">\(\ell(\sigma^*, \xi) \to \infty\)</span>: the search is thus restricted to <span class="math inline">\(\xi \geq -1\)</span>. These cases are more frequent in small samples due to the negative bias of the maximum likelihood estimator of the shape.</p>
<p>Except for this boundary case, the maximum likelihood estimator solves the score equation <span class="math inline">\(\partial \ell(\boldsymbol{\theta}) / \partial \boldsymbol{\theta} = \boldsymbol{0}_2\)</span>. We can thus check convergence by verifying that the score vanishes at the maximum likelihood estimate.</p>
<p>If <span class="math inline">\(\widehat{\xi} &lt; -0.5\)</span>, the asymptotic regime is nonstandard <span class="citation" data-cites="Smith:1985">(<a href="#ref-Smith:1985" role="doc-biblioref">Smith, 1985</a>)</span> and the standard errors obtained from the inverse information matrix are unreliable; as such, <code>mev</code> does not report them and prints an optional warning.</p>
<div class="cell" data-layout-align="center" data-fig.caption="Profile log likelihood of the generalized Pareto distribution" data-hash="likelihood_cache/html/gpprofile_b89e7d6c78887544e77e016184c3d5a1">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="likelihood_files/figure-html/gpprofile-1.png" class="img-fluid figure-img" width="768"></p>
</figure>
</div>
</div>
</div>
<p>The figure shows the profile likelihood for <span class="math inline">\(\eta = -\xi/\sigma\)</span> for two datasets, one of which (leftmost) achieves its maximum at <span class="math inline">\(\widehat{\xi} = -1\)</span> and <span class="math inline">\(\widehat{\eta} = 1/\max(\boldsymbol{y})\)</span>.</p>
<div class="cell" data-layout-align="center" data-fig.caption="Diagnostic plot for fitted model, with pointwise 0.95 confidence intervals from order statistics" data-hash="likelihood_cache/html/gp2_2baf2ae28f6d553708ea15156f6fa36a">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Only keep data from September to April</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>windlyon <span class="ot">&lt;-</span> <span class="fu">with</span>(</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>  frwind, </span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>  S2[lubridate<span class="sc">::</span><span class="fu">month</span>(date) <span class="sc">&lt;=</span> <span class="dv">4</span> <span class="sc">|</span> </span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>       lubridate<span class="sc">::</span><span class="fu">month</span>(date) <span class="sc">&gt;=</span> <span class="dv">9</span>])</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Keep only 100 largest points (fewer because of ties)</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>u <span class="ot">&lt;-</span> <span class="fu">quantile</span>(windlyon, </span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>              <span class="at">probs =</span> <span class="dv">1-100</span><span class="sc">/</span><span class="fu">length</span>(windlyon))</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit generalized Pareto via ML</span></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>fitted_gp <span class="ot">&lt;-</span> <span class="fu">fit.gpd</span>(</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">xdat =</span> windlyon,</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">threshold =</span> u,</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">show =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Method: Grimshaw 
Log-likelihood: -207.5276 

Threshold: 33.84 
Number Above: 90 
Proportion Above: 0.0079 

Estimates
  scale    shape  
3.57863  0.03088  

Standard Errors
 scale   shape  
0.6091  0.1337  

Optimization Information
  Convergence: successful </code></pre>
</div>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># P-P and Q-Q diagnostic plots </span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(fitted_gp)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="likelihood_files/figure-html/gp2-1.png" class="img-fluid figure-img" width="768"></p>
</figure>
</div>
</div>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="fu">graphics.off</span>()</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit exponential by passing a list with a fixed parameter</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>reduced_gp <span class="ot">&lt;-</span> <span class="fu">fit.gpd</span>(windlyon,</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>                   <span class="at">threshold =</span> u, </span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>                   <span class="at">fpar =</span> <span class="fu">list</span>(<span class="at">shape =</span> <span class="dv">0</span>))</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a><span class="co"># The MLE is sample mean of exceedances - check this</span></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a><span class="fu">isTRUE</span>(<span class="fu">coef</span>(reduced_gp) <span class="sc">==</span> <span class="fu">mean</span>(windlyon))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] TRUE</code></pre>
</div>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare nested models using likelihood ratio test</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(fitted_gp, reduced_gp)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Deviance Table

           npar Deviance Df  Chisq Pr(&gt;Chisq)    
fitted_gp     2   415.06                         
reduced_gp    1   502.50  1 87.448  &lt; 2.2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
<p>The <code>mev</code> package includes alternative routines for estimation, including the optimal bias-robust estimator of <span class="citation" data-cites="Dupuis:1999">Dupuis (<a href="#ref-Dupuis:1999" role="doc-biblioref">1999</a>)</span> and the approximate Bayesian estimators of <span class="citation" data-cites="Zhang.Stephens:2009">Zhang &amp; Stephens (<a href="#ref-Zhang.Stephens:2009" role="doc-biblioref">2009</a>)</span> and <span class="citation" data-cites="Zhang:2010">Zhang (<a href="#ref-Zhang:2010" role="doc-biblioref">2010</a>)</span>. The latter two are obtained by running a Markov chain Monte Carlo algorithm, but only the posterior mean and standard deviation are returned to reduce the memory footprint of the returned object, and these are calculated on the fly using running mean and variance estimators.</p>
<div class="cell" data-hash="likelihood_cache/html/gpalternative_1715b1f708c887744713fd65ddcca1f0">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Bayesian point estimates (based on MAP)</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="fu">fit.gpd</span>(windlyon, </span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>        <span class="at">threshold =</span> u, </span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>        <span class="at">show =</span> <span class="cn">TRUE</span>, </span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>        <span class="at">MCMC =</span> <span class="cn">TRUE</span>,</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>        <span class="at">method =</span> <span class="st">"zhang"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Method: Zhang 

Threshold: 33.84 
Number Above: 90 
Proportion Above: 0.0079 

Approximate posterior mean estimates
scale  shape  
3.456  0.066  

Posterior mean estimates
 scale   shape  
3.5594  0.0495  

Monte Carlo standard errors
scale  shape  
0.453  0.130  

Estimates based on an adaptive MCMC
 Runs:    10000 
 Burnin:  2000 
 Acceptance rate: 0.43 
 Thinning: 1 </code></pre>
</div>
</div>
<p>If the sample is small, maximum likelihood estimators are biased for the generalized Pareto distribution (the shape parameter is negatively biased, regardless of the true value for <span class="math inline">\(\xi\)</span>). Bias correction methods includes the modified score of Firth, but the default method is the implicit correction (<code>subtract</code>), which solves the implicit equation <span class="math display">\[\begin{align}
   \boldsymbol{\tilde{\theta}}=\hat{\boldsymbol{\theta}}-\boldsymbol{b}(\tilde{\boldsymbol{\theta}}). \label{eq:implbias}
\end{align}\]</span> The point estimate <span class="math inline">\(\boldsymbol{\tilde{\theta}}\)</span> is obtained numerically as the root of this nonlinear system of equations. In the present case, the sample size is large and hence the first-order correction, derived through asymptotic arguments from the generalized Pareto distribution likelihood, is small. Note that the bias correction requires <span class="math inline">\(\xi &gt; -1/3\)</span>, since it is based on third-order cumulants of the distribution.</p>
<div class="cell" data-hash="likelihood_cache/html/biascorr-gpd_deeb3a591d396bcce316d213e538eac9">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># First-order bias corrected estimates</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>corr_coef <span class="ot">&lt;-</span> <span class="fu">gpd.bcor</span>(<span class="at">par =</span> <span class="fu">coef</span>(fitted_gp), </span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>                      <span class="at">dat =</span> windlyon, </span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>                      <span class="at">corr =</span> <span class="st">"firth"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Error in bcor.st$value : $ operator is invalid for atomic vectors</code></pre>
</div>
</div>
</section>
<section id="inhomogeneous-poisson-process" class="level3">
<h3 class="anchored" data-anchor-id="inhomogeneous-poisson-process">Inhomogeneous Poisson process</h3>
<p>Let <span class="math inline">\(Y_{(1)} \geq \cdots \geq Y_{(r)}\)</span> denote the <span class="math inline">\(r\)</span> largest observations from a sample. The likelihood of the limiting distribution of the point process for the <span class="math inline">\(r\)</span>-largest observations is, for <span class="math inline">\(\mu,\xi\in\mathbb{R}, \sigma&gt;0\)</span>, [ (,,; ) -r() - (1+)<em>{j=1}^r (1 + )</em>{+} - (1 + )^{-1/}_+. ] This likelihood can be used to model the <span class="math inline">\(r\)</span>-largest observations per block or threshold exceedances where the threshold is the <span class="math inline">\(r\)</span>th order statistic</p>
<p>Consider a sample of <span class="math inline">\(N\)</span> observations, of which <span class="math inline">\(n_u\)</span> exceed <span class="math inline">\(u\)</span> and which we denote by <span class="math inline">\(y_1, \ldots, y_{n_u}\)</span>. The likelihood associated to the limiting distribution of threshold exceedances is, for <span class="math inline">\(\mu, \xi \in \mathbb{R}, \sigma &gt;0\)</span>, <span class="math display">\[\begin{align}
L(\mu, \sigma, \xi; \boldsymbol{y}) = \exp \left[ - c \left\{1+ \xi \left( \frac{u-\mu}{\sigma}\right)\right\}^{-1/\xi}_{+}\right] (c\sigma)^{-n_u}\prod_{i=1}^{n_u} \left\{1+\xi\left( \frac{y_i-\mu}{\sigma}\right)\right\}^{-1/\xi-1}_{+},\label{eq:ppp_lik}
\end{align}\]</span> where <span class="math inline">\((\cdot)_{+} = \max\{0, \cdot\}\)</span>. The quantity <span class="math inline">\(c\)</span> is a tuning parameter whose role is described in 7.5 of <span class="citation" data-cites="Coles:2001">Coles (<a href="#ref-Coles:2001" role="doc-biblioref">2001</a>)</span>. If we take <span class="math inline">\(c=N/m\)</span>, the parameters of the point process likelihood correspond to those of the generalized extreme value distribution fitted to blocks of size <span class="math inline">\(m\)</span>. The NHPP likelihood includes a contribution for the fraction of points that exceeds the threshold, whereas the generalized Pareto is a conditional distribution, whose third parameter is the normalizing constant <span class="math inline">\(\zeta_u=\Pr(Y&gt;u)\)</span>. Since the latter has a Bernoulli and <span class="math inline">\(\zeta_u\)</span> is orthogonal to the pair <span class="math inline">\((\sigma, \xi)\)</span>, it is often omitted from further analyses and estimated as the proportion of samples above the threshold.</p>
<p>The model includes additional arguments, <code>np</code> and <code>npp</code> (number of observations per period). If data are recorded on a daily basis, using a value of <code>npp = 365.25</code> yields location and scale parameters that correspond to those of the generalized extreme value distribution fitted to block maxima. Alternatively, one can specify instead the number of periods <code>np</code>, akin to <span class="math inline">\(n_y\)</span> in Eq. 7.8 of <span class="citation" data-cites="Coles:2001">Coles (<a href="#ref-Coles:2001" role="doc-biblioref">2001</a>)</span> — only the latter is used by the function, with <code>npp*np</code> theoretically equal to the number of exceedances.</p>
<p>The tuning parameters impact the convergence of the estimation since the dependence between parameters becomes very strong: <span class="citation" data-cites="Sharkey:2017">Sharkey &amp; Tawn (<a href="#ref-Sharkey:2017" role="doc-biblioref">2017</a>)</span> suggest to pick a value of <code>np</code> that near-orthogonalize the parameters. Wadsworth:2011 recommended picking this to be the number of observations (so <code>npp=1</code>), but <span class="citation" data-cites="Moins:arxiv">Moins et al. (<a href="#ref-Moins:arxiv" role="doc-biblioref">2023</a>)</span> show that a better choice leads to orthogonalization.</p>
<p>Another option is to fit the generalized Pareto model: if the probability of exceeding threshold <span class="math inline">\(u\)</span> is small, the Poisson approximation to binomial distribution implies [c {1+ ( )}^{-1/} n_u, ] where <span class="math inline">\(n_u\)</span> is the number of threshold exceedances above <span class="math inline">\(u\)</span> and <span class="math inline">\(c\)</span> is the tuning parameter <code>np</code>. With the point estimates of the generalized Pareto model, say <span class="math inline">\((\widehat{\sigma}_u, \widehat{\xi})\)</span>, we thus use <span class="math display">\[\begin{align*}
\mu_0 &amp;= u - \sigma_0\{(n_u/c)^{-\widehat{\xi}}-1\}/\widehat{\xi},\\
\sigma_0 &amp;= \widehat{\sigma}_u\times (n_u/c)^{\widehat{\xi}},
\end{align*}\]</span> and <span class="math inline">\(\xi_0=\widehat{\xi}\)</span> as starting values. Most of the time, these values are so close to the solution of the score equation that numerical convergence of the optimization routine is all but guaranteed in a few likelihood evaluations. If no starting value is provided and some fixed parameters are provided, the model will approximate the distribution of the vector of parameters by a multivariate Gaussian distribution and compute the best linear predictor of the remaining parameters given those are fixed. This method works well if the log-likelihood is near quadratic and the values are not too far from the maximum, but does not deal with the boundary constraints. In case these starting values are invalid, and an error message is returned.</p>
<p>The log likelihood of the <span class="math inline">\(r\)</span> largest order statistics likelihood is derived from the inhomogenenous Poisson point process formulation. We normally consider a matrix of observations <span class="math inline">\(m \times r\)</span> containing the largest <span class="math inline">\(r\)</span> order statistics of each block out of the <span class="math inline">\(n\)</span> sample. The parameters of the <span class="math inline">\(r\)</span>-largest likelihood are the same as the generalized extreme value distribution (a special case when <span class="math inline">\(r=1\)</span>). This model can be used when we have access to order statistics, assuming that the observations within the block are independent.</p>
<p><span class="math display">\[\begin{align*}
\ell(\mu,\sigma,\xi; \boldsymbol{y}) &amp;= -rm\log(\sigma) - \left(1+\frac{1}{\xi}\right)\sum_{i=1}^m\sum_{j=1}^r \log\left(1 + \xi\frac{y_{i,(j)}-\mu}{\sigma}\right)_{+} \\ &amp;\quad- \left(1 + \xi\frac{y_{i,(r)}-\mu}{\sigma}\right)^{-1/\xi}_+, \quad \mu,\xi\in\mathbb{R}, \sigma&gt;0. \label{eq:rlarglik}
\end{align*}\]</span> It’s not obvious how to chose <span class="math inline">\(r\)</span>, but <span class="citation" data-cites="Belzile:2022">Belzile &amp; Davison (<a href="#ref-Belzile:2022" role="doc-biblioref">2022</a>)</span> shows the gain from considering larger values of <span class="math inline">\(r\)</span> decreases quickly for the shape. The support constraints, typically arising for the minimum observation, means that finding good starting values is hard.</p>
<p>We can simulate from the <span class="math inline">\(r\)</span> largest observations by drawing from a unit rate Poisson process <span class="math inline">\(0&lt;U_1&lt;U_2&lt;\cdots\)</span>, where <span class="math inline">\(U_j=E_1+\cdots+E_j\)</span> and <span class="math inline">\(E_j\sim \mathsf{Exp}(1)\)</span>, and setting <span class="math inline">\(Y_{j} = \mu + \sigma\big(U_j^{-1/\xi}-1\big)/\xi\)</span>. Applying the inverse transformation <span class="math inline">\(\Lambda_{\boldsymbol{\theta}}(y) = \left\{ 1 + \xi(y-\mu)/\sigma\right\}^{-1/\xi}_+\)</span> evaluated at the MLE gives roughly independent exponential spacings, which can be used to create quantile-quantile plots.</p>
</section>
</section>
<section id="risk-measures" class="level2">
<h2 class="anchored" data-anchor-id="risk-measures">Risk measures</h2>
<p>Two typical questions in extreme values are: given the intensity of an extreme event, what is its recurrence period? and what is a typical worst-case scenario over a given period of time? For the latter, suppose for simplicity that the daily observations are blocked into years, so that inference is based on <span class="math inline">\(N\)</span> points for the <span class="math inline">\(N\)</span> years during which the data were recorded. The <em>return level</em> is a quantile of the underlying distribution corresponding to an event of probability <span class="math inline">\(p=1-1/T\)</span> for an annual maximum, which is interpreted as ``the level exceeded by an annual maximum on average every <span class="math inline">\(T\)</span> years’’. If observations are independent and identically distributed, then we can approximate the probability that a return level is exceeded <span class="math inline">\(l\)</span> times over a <span class="math inline">\(T\)</span> year period using a binomial distribution with probability of success <span class="math inline">\(1-1/T\)</span> and <span class="math inline">\(T\)</span> trials. For <span class="math inline">\(T\)</span> large, the return level is exceeded <span class="math inline">\(l=0, 1, 2, 3, 4\)</span> times within any <span class="math inline">\(T\)</span>-years period with approximate probabilities 36.8%, 36.8%, 18.4%, 6.1% and 1.5%. The probability that the maximum observation over <span class="math inline">\(T\)</span> years is exceeded with a given probability is readily obtained from the distribution of the <span class="math inline">\(T\)</span>-year maximum, leading <span class="citation" data-cites="Cox:2002">(<a href="#ref-Cox:2002" role="doc-biblioref">Cox et al., 2002, p. 3(b)</a>)</span> to advocate its use over return levels, among other quantities of interest such as the number of times a threshold <span class="math inline">\(u\)</span> will be exceeded in <span class="math inline">\(T\)</span> years or the average number of years before a threshold <span class="math inline">\(u\)</span> is exceeded.</p>
<p><strong>Quantiles, mean and return levels of <span class="math inline">\(T\)</span>-maxima</strong>: consider the distribution <span class="math inline">\(H(x) = G^T(x)\)</span> of the maximum of <span class="math inline">\(T\)</span> independent and identically distributed generalized extreme value variates with parameters <span class="math inline">\((\mu, \sigma, \xi)\)</span> and distribution function <span class="math inline">\(G\)</span>. By max-stability, the parameters of <span class="math inline">\(H(x)\)</span> are <span class="math inline">\(\mu_T=\mu-\sigma(1-T^\xi)/\xi\)</span> and <span class="math inline">\(\sigma_T=\sigma T^\xi\)</span> when <span class="math inline">\(\xi \neq 0\)</span>. We denote the expectation of the <span class="math inline">\(T\)</span>-observation maximum by <span class="math inline">\(\mathfrak{e}_T\)</span>, the <span class="math inline">\(p\)</span> quantile of the <span class="math inline">\(T\)</span>-observation maximum by <span class="math inline">\(\mathfrak{q}_p = H^{-1}(p)\)</span> and the associated return level by <span class="math inline">\(z_{1/T} = G^{-1}(1-1/T)\)</span>. Then, any of these three quantities can be written as <span class="math display">\[\begin{align*}
\begin{cases}
\mu-\frac{\sigma}{\xi}\left\{1-\kappa_{\xi}\right\}, &amp;  \xi &lt;1, \xi \neq 0, \\
\mu+\sigma\kappa_0, &amp;  \xi =0,
  \end{cases}
\end{align*}\]</span> where <span class="math inline">\(\kappa_{\xi}=T^\xi\Gamma(1-\xi)\)</span> for <span class="math inline">\(\mathfrak{e}_T\)</span>, <span class="math inline">\(\kappa_{\xi}=T^\xi\log(1/p)^{-\xi}\)</span> for <span class="math inline">\(\mathfrak{q}_p\)</span> and <span class="math inline">\(\kappa_{\xi}=\left\{-\log\left(1-{1}/{T}\right)\right\}^{-\xi}\)</span> for <span class="math inline">\(z_{1/T}\)</span>. In the Gumbel case, we have <span class="math inline">\(\kappa_0=\log(T)+\gamma_{e}\)</span> for <span class="math inline">\(\mathfrak{e}_T\)</span>, <span class="math inline">\(\kappa_0=\log(T)-\log\{-\log(p)\}\)</span> for <span class="math inline">\(\mathfrak{q}_p\)</span> and <span class="math inline">\(\kappa_0=-\log\{-\log(1-1/T)\}\)</span> for <span class="math inline">\(z_{1/T}\)</span>.</p>
</section>
<section id="references" class="level2">




</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-line-spacing="2" role="list">
<div id="ref-Belzile:2022" class="csl-entry" role="listitem">
Belzile, L. R., &amp; Davison, A. C. (2022). Improved inference on risk measures for univariate extremes. <em>The Annals of Applied Statistics</em>, <em>16</em>(3), 1524–1549. <a href="https://doi.org/10.1214/21-AOAS1555">https://doi.org/10.1214/21-AOAS1555</a>
</div>
<div id="ref-Coles:2001" class="csl-entry" role="listitem">
Coles, S. (2001). <em>An <span>I</span>ntroduction to <span>S</span>tatistical <span>M</span>odeling of <span>E</span>xtreme <span>V</span>alues</em> (p. 209). Springer–Verlag.
</div>
<div id="ref-Cox:2002" class="csl-entry" role="listitem">
Cox, D. R., Isham, V. S., &amp; Northrop, P. J. (2002). Floods: Some probabilistic and statistical approaches. <em>Philosophical Transactions of the Royal Society of London A: Mathematical, Physical and Engineering Sciences</em>, <em>360</em>(1796), 1389–1408. <a href="https://doi.org/10.1098/rsta.2002.1006">https://doi.org/10.1098/rsta.2002.1006</a>
</div>
<div id="ref-Dupuis:1999" class="csl-entry" role="listitem">
Dupuis, D. J. (1999). Exceedances over high thresholds: A guide to threshold selection. <em>Extremes</em>, <em>1</em>(3), 251–261. <a href="https://doi.org/10.1023/A:1009914915709">https://doi.org/10.1023/A:1009914915709</a>
</div>
<div id="ref-Grimshaw:1993" class="csl-entry" role="listitem">
Grimshaw, S. D. (1993). Computing maximum likelihood estimates for the generalized <span>P</span>areto distribution. <em>Technometrics</em>, <em>35</em>(2), 185–191. <a href="https://doi.org/10.1080/00401706.1993.10485040">https://doi.org/10.1080/00401706.1993.10485040</a>
</div>
<div id="ref-Moins:arxiv" class="csl-entry" role="listitem">
Moins, T., Arbel, J., Girard, S., &amp; Dutfoy, A. (2023). Reparameterization of extreme value framework for improved <span>B</span>ayesian workflow. <em>Computational Statistics &amp; Data Analysis</em>, <em>to appear</em>. https://doi.org/<a href="https://doi.org/10.1016/j.csda.2023.107807">https://doi.org/10.1016/j.csda.2023.107807</a>
</div>
<div id="ref-Sharkey:2017" class="csl-entry" role="listitem">
Sharkey, P., &amp; Tawn, J. A. (2017). A <span>P</span>oisson process reparameterisation for <span>B</span>ayesian inference for extremes. <em>Extremes</em>, <em>20</em>(2), 239–263. <a href="https://doi.org/10.1007/s10687-016-0280-2">https://doi.org/10.1007/s10687-016-0280-2</a>
</div>
<div id="ref-Smith:1985" class="csl-entry" role="listitem">
Smith, R. L. (1985). Maximum likelihood estimation in a class of nonregular cases. <em>Biometrika</em>, <em>72</em>(1), 67–90. <a href="https://doi.org/10.1093/biomet/72.1.67">https://doi.org/10.1093/biomet/72.1.67</a>
</div>
<div id="ref-Zhang:2010" class="csl-entry" role="listitem">
Zhang, J. (2010). Improving on estimation for the generalized pareto distribution. <em>Technometrics</em>, <em>52</em>(3), 335–339. <a href="https://doi.org/10.1198/TECH.2010.09206">https://doi.org/10.1198/TECH.2010.09206</a>
</div>
<div id="ref-Zhang.Stephens:2009" class="csl-entry" role="listitem">
Zhang, J., &amp; Stephens, M. A. (2009). A new and efficient estimation method for the generalized <span>P</span>areto distribution. <em>Technometrics</em>, <em>51</em>(3), 316–325. <a href="https://doi.org/10.1198/tech.2009.08017">https://doi.org/10.1198/tech.2009.08017</a>
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left"><a href="https://dec.unibocconi.eu/research/extreme-value-analysis-eva-2023">EVA 2023</a></div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">Website built with <a href="https://quarto.org/">Quarto</a></div>
  </div>
</footer>



</body></html>